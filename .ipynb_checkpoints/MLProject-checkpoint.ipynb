{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1eG6xkvG-0Sa"
   },
   "source": [
    "# Term 6 Machine Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YGlqoAc-0Sb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lm74kA3Y-0S3"
   },
   "outputs": [],
   "source": [
    "running = \"SG\"\n",
    "\n",
    "filesgtrain = \"SG/train\"\n",
    "filecntrain = \"CN/train\"\n",
    "fileentrain = \"EN/train\"\n",
    "filefrtrain = \"FR/train\"\n",
    "\n",
    "filesg = \"SG/dev.in\"\n",
    "filecn=\"CN/dev.in\"\n",
    "fileen=\"EN/dev.in\"\n",
    "filefr=\"FR/dev.in\"\n",
    "\n",
    "if running == \"SG\":\n",
    "    filetrain = filesgtrain\n",
    "    filetest = filesg\n",
    "elif running == \"EN\":\n",
    "    filetrain = fileentrain\n",
    "    filetest = filensg\n",
    "elif running == \"CN\":\n",
    "    filetrain = filecntrain\n",
    "    filetest = filecn\n",
    "elif running == \"FR\":\n",
    "    filetrain = filefrtrain\n",
    "    filetest = filefr\n",
    "else:\n",
    "    print(\"Invalid set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "CFtT49w4_b7_",
    "outputId": "4a7f3fc2-79e9-41d9-d894-7b9482ce725b"
   },
   "outputs": [],
   "source": [
    "# Used when running on gcolab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# # use /content/gdrive/My Drive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7vBvWP1-0Sh"
   },
   "source": [
    "## Part 2 & 3 Training data Processing\n",
    "\n",
    "Algorithm:  \n",
    "for loop tweets, tags:  \n",
    "add each tag into a dictionary. (key:tags, values:\\[words\\])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGGvGi5d-0Si"
   },
   "outputs": [],
   "source": [
    "def file_to_df(inputfile):\n",
    "    \"\"\"\n",
    "    Function to process input file to dataframe\n",
    "    inputfile: File to be processed\n",
    "\n",
    "    Returns:\n",
    "    df: Output dataframe\n",
    "    all_tags: unique tags\n",
    "    all_words: dictionary of all words with tag as key\n",
    "    k_of_dict = dictionary of unknown var k\n",
    "    \"\"\"\n",
    "\n",
    "    fin = open(inputfile,encoding=\"UTF-8\")\n",
    "    rawframe=[]\n",
    "    all_tags = [] # List holding All unique Tags\n",
    "    all_words = {} # dictionary of all words with tag as key\n",
    "    k_of_dict={}\n",
    "    for line in fin:\n",
    "        if len(line) == 0: continue\n",
    "        cols = re.split('\\s+(?=\\S+$)',line) #Using the last whitespace as separator\n",
    "        if len(cols) > 1:\n",
    "            tag = cols[1].strip()\n",
    "            word = cols[0].strip()\n",
    "            if tag not in all_tags:\n",
    "                all_tags.append(tag)\n",
    "            if tag not in all_words:\n",
    "                all_words[tag] = [word]\n",
    "                k_of_dict[tag] = 1\n",
    "            else:\n",
    "                all_words[tag].append(word)\n",
    "        rawframe.append(cols)\n",
    "\n",
    "    df = pd.DataFrame(rawframe, columns = [\"Word\", \"Tag\"])\n",
    "    df[\"transit\"] = None # Create an extra column for transition start/end for states\n",
    "    print(\"File Processing Completed\")\n",
    "    return df, all_tags, all_words, k_of_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4A5YfUSf-0Sk"
   },
   "source": [
    "## Part 2a For Emission w/o including UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r87emic-0Sl"
   },
   "outputs": [],
   "source": [
    "def get_emission_probability(x,y,all_words):\n",
    "\n",
    "    '''\n",
    "    Retrieves emission probability\n",
    "    x: String value which is the emitted word\n",
    "    y: String value which is the given tag\n",
    "    all_words: dictionary of all words with tag as key\n",
    "    \n",
    "    Returns float probability of emitting x from y\n",
    "    If invalid parameters, return None\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        total_y_words = len(all_words[y])\n",
    "        total_tag_to_word = all_words[y].count(x)\n",
    "        return total_tag_to_word/total_y_words\n",
    "    except:\n",
    "        return 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiy0zF5J-0Sn"
   },
   "source": [
    "## Part 2b For Emission including UNK\n",
    "During the testing phase, if word does not appear in the training set, we replace the word with the special word token #UNK#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VMbFskB-0Sn"
   },
   "outputs": [],
   "source": [
    "def test_get_emission_probability(x, y, k_of_dict, all_words):\n",
    "    '''\n",
    "    Returns float probability of emitting x from y, accounting in #UNKN#\n",
    "    If invalid parameters, return None\n",
    "    x: String value which is the emitted word\n",
    "    y: String value which is the given tag\n",
    "    k_of_dict: dictionary of unknown var k\n",
    "    all_words: dictionary of all words with tag as key\n",
    "    '''\n",
    "    global_counter=0\n",
    "    for i in all_words:\n",
    "        if all_words[i].count(x)!=0:\n",
    "            global_counter+=1\n",
    "\n",
    "    try:\n",
    "        total_y_words = len(all_words[y])\n",
    "        total_tag_to_word = all_words[y].count(x)\n",
    "        if global_counter == 0:\n",
    "            calculatedprob = float(1 / (total_y_words + 1))\n",
    "            return calculatedprob\n",
    "        else:\n",
    "            calculatedprob = float(total_tag_to_word / (total_y_words + 1))\n",
    "            return calculatedprob\n",
    "    except:\n",
    "        return 0.0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VD1oXTi-0Sq"
   },
   "source": [
    "## Part 2c Emission on test data\n",
    "argmax word to tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q2g_KTk-0St"
   },
   "outputs": [],
   "source": [
    "def preprocess_unk(filetest,filename):\n",
    "    kw_dict = {}\n",
    "    inputFile = open(filename, 'r', encoding=\"UTF-8\")\n",
    "    for line in inputFile:\n",
    "        line = line.strip().split()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            line = line[0].lower()\n",
    "        if line in kw_dict:\n",
    "            continue\n",
    "        else:\n",
    "            kw_dict[line] = 1\n",
    "    inputList = []\n",
    "    word_column = open(filetest, 'r', encoding=\"UTF-8\")\n",
    "    for each_word in word_column:\n",
    "        each_word = each_word.lower().strip()\n",
    "        if each_word=='':\n",
    "            inputList.append(None) # input blank lines with blank word. replace it later\n",
    "        elif kw_dict.get(each_word)==1:\n",
    "            inputList.append(each_word)\n",
    "        else:\n",
    "            inputList.append(\"#UNK#\")\n",
    "\n",
    "    df = pd.DataFrame(inputList, columns=[\"Word\"])\n",
    "    print(\"File Processing Completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZpO4UMw-0Sv"
   },
   "outputs": [],
   "source": [
    "def tag_creator(word_column, k_of_dict, all_words):\n",
    "    '''\n",
    "    Returns the most probable word, calls test_get_emission_probability inside\n",
    "    word_column: df column of words to predict\n",
    "    k_of_dict: dictionary of unknown var k\n",
    "    all_words: dictionary of all words with tag as key\n",
    "    '''\n",
    "    tag_column=[]\n",
    "    data_length = word_column.shape[0]\n",
    "    completed_length = 0\n",
    "    for x in word_column:\n",
    "        completed_length += 1\n",
    "        print(\"Working on {}/{}\".format(completed_length,data_length), end='\\r', flush=True)\n",
    "        if x == None:\n",
    "            tag_column.append(None)\n",
    "        else:\n",
    "            highest_prob = 0.0\n",
    "            most_probable = \"\"\n",
    "            for key in all_words:\n",
    "                curr_prob = test_get_emission_probability(x, key, k_of_dict, all_words)\n",
    "                if curr_prob > highest_prob:\n",
    "                    highest_prob = curr_prob\n",
    "                    most_probable = key\n",
    "            tag_column.append(most_probable)\n",
    "        \n",
    "    print(\"Tags Created\")\n",
    "    return tag_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "r6BQneZS-0Sx",
    "outputId": "946c63f2-0de1-4f9b-f95d-bd301ab9b6d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Part 2a----------\n",
      "File Processing Completed\n",
      "Testing emission of trump as B-Positive, probability: 0.00030609121518212427\n",
      "\n",
      "----------Part 2b----------\n",
      "Testing emission of kahwee as B-Positive, probability: 0.0001530221882172915\n",
      "\n",
      "----------Part 2c----------\n",
      "File Processing Completed\n",
      "Working on 4548/44106\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-296c531fc889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------Part 2c----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0moutframe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_unk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiletest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiletrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutframe2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tag\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutframe2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_of_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# outframe2.to_csv(\"SG/devSG.out\", sep=\" \", index=False, header=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d7d0e09d75cf>\u001b[0m in \u001b[0;36mtag_creator\u001b[0;34m(word_column, k_of_dict, all_words)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmost_probable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mcurr_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_get_emission_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_of_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurr_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhighest_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mhighest_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-39bc0df3afd0>\u001b[0m in \u001b[0;36mtest_get_emission_probability\u001b[0;34m(x, y, k_of_dict, all_words)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mglobal_counter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mglobal_counter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Testing out Part 2a\n",
    "print('----------Part 2a----------')\n",
    "df, all_tags, all_words, k_of_dict = file_to_df(filetrain)\n",
    "print(\"Testing emission of trump as B-Positive, probability: {}\".format(get_emission_probability(\"trump\",\"B-positive\", all_words)))\n",
    "print()\n",
    "\n",
    "# Testing out part 2b\n",
    "print('----------Part 2b----------')\n",
    "print(\"Testing emission of kahwee as B-Positive, probability: {}\".format(test_get_emission_probability(\"kahwee\",\"B-positive\", k_of_dict, all_words)))\n",
    "print()\n",
    "\n",
    "# Testing out part 2c and produce dev.out\n",
    "print('----------Part 2c----------')\n",
    "outframe2 = preprocess_unk(filetest,filetrain)\n",
    "outframe2[\"Tag\"]=tag_creator(outframe2[\"Word\"], k_of_dict, all_words)\n",
    "# outframe2.to_csv(\"SG/devSG.out\", sep=\" \", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "id": "2WDedDIH-0Sz",
    "outputId": "2c2a426d-dc43-42e8-c6de-c226e0b1a9b7"
   },
   "outputs": [],
   "source": [
    "outframe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqCL_-os-0S5"
   },
   "source": [
    "## Part 3 Processing For Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aqf30G8B-0S6"
   },
   "outputs": [],
   "source": [
    "def startEndCol(df):\n",
    "    \"\"\"\n",
    "    This function label the new column as either start or end based on the position of the \"None\" tag in the Tag Column.\n",
    "    df: This is the dataframe generated from Part 2 without start and end. Dataframe needs to have columns Word, Tag, transit\n",
    "    \"\"\"\n",
    "    dataframeSize = len(df.index)\n",
    "    df.loc[0]['transit']= \"Start\"\n",
    "    df.loc[dataframeSize-2]['transit']='End'\n",
    "    counter = 0\n",
    "    for rows in df.iterrows():\n",
    "        if rows[1][1]==None and counter<dataframeSize-1:\n",
    "            df.loc[counter-1]['transit'] = \"End\"\n",
    "            df.loc[counter+1]['transit'] = \"Start\"\n",
    "            counter+=1\n",
    "        else: counter+=1\n",
    "    print(\"Start End Columns Assigned\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aycfej90-0S7"
   },
   "source": [
    "## Part 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fh4T5xzw-0S7"
   },
   "outputs": [],
   "source": [
    "def transition_creation(transitionframe):\n",
    "    '''\n",
    "    Creates a dictionary of transitions\n",
    "    transitionframe: dataframe to be that transitions will be based on\n",
    "    \n",
    "    Returns:\n",
    "    transition_dict: dictionary with transitions from transition frame\n",
    "    '''\n",
    "    transition_dict = {\"Start\": [], \"End\":[]}\n",
    "    transitionframe = transitionframe.replace('\\n','', regex=True)\n",
    "    previous_Tag = \"Starter\"\n",
    "    for index, row in transitionframe.iterrows():\n",
    "        current_Tag = row[\"Tag\"]\n",
    "        if previous_Tag == \"Starter\":\n",
    "            previous_Tag == current_Tag\n",
    "        if row['transit'] == \"Start\":\n",
    "            transition_dict[\"Start\"].append(current_Tag)\n",
    "        elif row[\"transit\"]==\"End\":\n",
    "            transition_dict[current_Tag].append(\"End\")\n",
    "        else:\n",
    "            if previous_Tag not in transition_dict:\n",
    "                transition_dict[previous_Tag] = [current_Tag]\n",
    "            else:\n",
    "                transition_dict[previous_Tag].append(current_Tag)\n",
    "        previous_Tag = current_Tag\n",
    "    print(\"Transition Dictionary Created\")\n",
    "    return transition_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_transition_probability(y1,y2,transition_dict):\n",
    "    '''\n",
    "    Calculates the probability of y1 going into y2\n",
    "    y1: previous tag\n",
    "    y2: probable tag\n",
    "    transition_dict: dictionary of transitions\n",
    "    \n",
    "    Returns:\n",
    "    probability of y1 going into y2\n",
    "    \n",
    "    '''\n",
    "    count_y1_y2 = transition_dict[y1].count(y2)\n",
    "    count_y1 = len(transition_dict[y1])\n",
    "    probability = count_y1_y2/count_y1\n",
    "    return float(probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dg8oQRD2-0TE"
   },
   "source": [
    "## Part 3b\n",
    "Predict Label  \n",
    "Given the obsercation sequence, find the most optimum sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5cPIZ0c-0S9"
   },
   "outputs": [],
   "source": [
    "def preprocess_viterbi(in_file):\n",
    "    '''\n",
    "    1.Preprocess csv file with only words input,\n",
    "    2.Replace space lines as \"EndOfSentence\"\n",
    "    3.Inserting start/end indicators for sentences,\n",
    "    4.Remove the \"EOS\" tag at the end\n",
    "    5.Reset the index\n",
    "    6.Add previous tag and current tag columns\n",
    "    7.Set First column to Start\n",
    "    \n",
    "    '''\n",
    "    inputList=[]\n",
    "    inputFile = open(in_file, 'r')\n",
    "    for line in inputFile:\n",
    "        if(line.strip()==\"\"):\n",
    "            line = \"EOS\"\n",
    "        else:line = line.strip()\n",
    "        if len(line) == 0:continue\n",
    "        inputList.append(line)\n",
    "    df = pd.DataFrame(inputList, columns = [\"Word\"])\n",
    "    df['transit'] = \"Empty\"\n",
    "    counter=0\n",
    "    dataframeSize = len(df.index)\n",
    "    df.loc[0]['transit']= \"Start\"\n",
    "    df.loc[dataframeSize-2]['transit']='End'\n",
    "    for index,rows in df.iterrows():\n",
    "        if rows[\"Word\"]==\"EOS\" and counter<dataframeSize-1:\n",
    "            df.loc[counter-1]['transit'] = \"End\"\n",
    "            df.loc[counter+1]['transit'] = \"Start\"\n",
    "            counter+=1\n",
    "        else: counter+=1\n",
    "    df = df.replace('EOS','', regex=True)\n",
    "    df=df.reset_index(drop=True)\n",
    "    df['previous_tag'] = 'not entered yet'\n",
    "    df['previous_tag'][0] = 'Start'\n",
    "    df['Tag'] = 'not entered yet'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DJVAVbz-0TE"
   },
   "outputs": [],
   "source": [
    "def viterbi(sentence, sentence_index, outframe, transition_dict, k_of_dict, all_words):\n",
    "    '''\n",
    "    Returns most probable tag for a given transition and word\n",
    "    sentence: array of words in sentence\n",
    "    sentence_index: array of index for words in sentence\n",
    "    outframe: dataframe to change\n",
    "    transition_dict: dictionary of transitions\n",
    "    k_of_dict: dictionary of unknown var k\n",
    "    all_words: dictionary of all words with tag as key\n",
    "    '''\n",
    "    tag_track = []\n",
    "    for tag in all_words:\n",
    "        tag_track.append(tag)\n",
    "    table_width = len(all_words) + 1\n",
    "    prob_table = []\n",
    "    for i in range(len(sentence)+1):\n",
    "        row = []\n",
    "        for j in range(len(tag_track)):\n",
    "            if i==0:\n",
    "                ij_transition = test_get_transition_probability(\"Start\", tag_track[j], transition_dict)\n",
    "                ij_emission = test_get_emission_probability(sentence[i], tag_track[j], k_of_dict, all_words)\n",
    "                ij_value = ij_transition*ij_emission\n",
    "                row.append((ij_value, \"Start\"))\n",
    "            elif i==len(sentence):\n",
    "                ij_previous = prob_table[i-1][j][0]\n",
    "                if ij_previous == 0:\n",
    "                    row.append((0, j))\n",
    "                    continue\n",
    "                ij_transition = test_get_transition_probability(tag_track[j], \"End\", transition_dict)\n",
    "                ij_value = ij_transition*ij_previous\n",
    "                row.append((ij_value, j))\n",
    "            else:\n",
    "                largest_value = 0\n",
    "                largest_index = 0\n",
    "                for k in range(len(tag_track)):\n",
    "                    kj_previous = prob_table[i-1][k][0]\n",
    "                    if kj_previous == 0:\n",
    "                        continue\n",
    "                    kj_transition = test_get_transition_probability(tag_track[k], tag_track[j], transition_dict)\n",
    "                    kj_emission = test_get_emission_probability(sentence[i], tag_track[j], k_of_dict, all_words)\n",
    "                    kj_value = kj_transition*kj_emission*kj_previous\n",
    "                    if kj_value > largest_value:\n",
    "                        largest_value = kj_value\n",
    "                        largest_index = k\n",
    "                row.append((largest_value,largest_index))\n",
    "        prob_table.append(row)\n",
    "        \n",
    "    sequence = []\n",
    "    highest_prob = 0\n",
    "    previous_tag = 0\n",
    "    for i in range(len(prob_table[len(sentence)-1])):\n",
    "        compare_prob = prob_table[len(sentence)-1][i][0]\n",
    "        if compare_prob > highest_prob:\n",
    "            highest_prob = compare_prob\n",
    "            previous_tag = prob_table[len(sentence)-1][i][1]\n",
    "    for i in range(len(prob_table)-1):\n",
    "        sequence.append(tag_track[previous_tag])\n",
    "        previous_tag = prob_table[len(prob_table)-i-2][previous_tag][1]\n",
    "        \n",
    "    sequence.reverse()\n",
    "    \n",
    "    for i in range(len(sentence_index)):\n",
    "        outframe.loc[sentence_index[i]][\"Tag\"] = sequence[i]\n",
    "    return sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 26939
    },
    "colab_type": "code",
    "id": "TdDN3JxY-0TH",
    "outputId": "82eaf533-7349-45aa-e6dd-43e02c187fb6"
   },
   "outputs": [],
   "source": [
    "def viterbi_on_df(outframe, transition_dict, k_of_dict, all_words):\n",
    "    \"\"\"\n",
    "    Process the viterbi algorithm via row by row of the dataframe\n",
    "    1. Takes into account of transit(Start and ending of a sentence)\n",
    "    2. \n",
    "    \"\"\"\n",
    "    df_size = outframe.shape[0]\n",
    "    is_sentence = False\n",
    "    sentence = []\n",
    "    sentence_index = []\n",
    "    for index, row in outframe.iterrows():\n",
    "        if row[\"Word\"] == \"\":\n",
    "            continue\n",
    "        sentence.append(row['Word'])\n",
    "        sentence_index.append(index)\n",
    "        if row[\"transit\"] == \"End\":\n",
    "            is_sentence = True\n",
    "        if is_sentence:\n",
    "            output = viterbi(sentence, sentence_index, outframe, transition_dict, k_of_dict, all_words)\n",
    "            is_sentence = False\n",
    "            sentence = []\n",
    "            sentence_index = []\n",
    "        if index >= outframe.shape[0]: break\n",
    "        print(\"Working on {}/{}\".format(index,df_size), end='\\r', flush=True)\n",
    "    return outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionframe = startEndCol(df)\n",
    "# Removing columns with [Tag] Column=None\n",
    "transitionframe = transitionframe[~transitionframe['Tag'].isin([None])]\n",
    "# print(transitionframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Part 3a\n",
    "print('----------Part 3a----------')\n",
    "transition_dict = transition_creation(transitionframe)\n",
    "print(\"Testing transition of B-positive to I-positive, probability: {}\".format(test_get_transition_probability(\"B-positive\",\"I-positive\", transition_dict)))\n",
    "print()\n",
    "\n",
    "# Testing Part 3b\n",
    "print('----------Part 3b----------')\n",
    "outframe = preprocess_viterbi(filetest)\n",
    "outframe = viterbi_on_df(outframe, transition_dict, k_of_dict, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "id": "UGEd3fWG-0TB",
    "outputId": "00576f5d-554b-4df2-940d-c15b01bd4a79"
   },
   "outputs": [],
   "source": [
    "outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLProject.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
